# 输入输出数据方案

## 输入描述
- 输入文件 $X = \{x_1, x_2, \dots, x_n\}$ 来源于 `data/sample_article.txt`。
- 每个样本 $x_i$ 为按句切分的文本片段，满足 $|x_i| \leq 200$。
- 预处理函数 $f_{\text{clean}}: X \rightarrow X'$ 去除前后空白、保留原有语义符号。

## 输出描述
- 输出集合 $Y = [y_1, y_2, \dots, y_m]$ 存储于 `data/chinese_name_frequency_word.json`。
- $y_k$ 可以是中文命名实体或混合字母串（如 `P450`），保持去重且按频次降序排序。
- 采用 JSON 数组编码，元素为字典 $\{\text{id}, \text{word}\}$，其中 `id` 记录带前缀的编号，`word` 满足字符集约束 $y_k \in (\mathbb{C} \cup \mathbb{A})^+$。
- 编号策略：姓名词表使用前缀 `1`（示例 `11` 表示第 1 条），常用词表使用前缀 `2`（示例 `2187` 表示第 187 条）。
- 构造字符二元参考集合 $B = \{ b \mid b \in \mathcal{D}, |b|=2 \}$，其中 $\mathcal{D}$ 为 `data/chinese_frequency_word.json` 与 `data/chinese_name_frequency_word.json` 的并集；字符模式下以真值二元组 $g_t$ 的首字符与预测字符 $\hat{y}_t$ 形成 $b_t = g_t[0] \Vert \hat{y}_t$，命中集合直接奖励，未命中但 $\hat{y}_t = g_t[1]$ 时触发回退奖励，并同时按照 $0.5/0.25$ 权重注入质量信号。
- 对于每个字符级步骤，将 $b_t$ 以字符串形式写入指标 `lexical_bigram_candidate`，供日志展示与评分回放使用。

## 数据流程伪代码
```pseudo
function TransformIO(text_path, json_path):
    raw_text <- read(text_path)
    segments <- chunk(raw_text, max_len=200)
    entities <- []
    for batch in batch_split(segments, size=16):
        ner_batch <- ltp.pipeline(batch, tasks=["cws", "ner"])
        entities.append(filter_tags(ner_batch))
    ascii_tokens <- regex_extract(raw_text)
    bigram_vocab <- load_bigrams(["data/chinese_frequency_word.json", "data/chinese_name_frequency_word.json"])
    merged <- normalize(entities, ascii_tokens)
    sorted_list <- sort_by_frequency(merged)
    register_character_reward(bigram_vocab)  # 环境内部按 base=0.5、potential=0.25、fallback=0.5 调整字符模式奖励
    write_json(json_path, sorted_list)
```
