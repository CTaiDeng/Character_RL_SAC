# 网络拓扑结构方案

## 拓扑定义
- 构建有向图 $G = (V, E)$，节点集合
  $$V = \{v_1, v_2, v_3, v_4, v_5\} = \{\text{预处理}, \text{LTP-NER}, \text{ASCII提取}, \text{归一化}, \text{汇总输出}\}.$$
- 边集合
  $$E = \{(v_1, v_2), (v_1, v_3), (v_2, v_4), (v_3, v_4), (v_4, v_5)\}.$$
- 拓扑矩阵表示
  $$A =
  \begin{bmatrix}
  0 & 1 & 1 & 0 & 0 \\
  0 & 0 & 0 & 1 & 0 \\
  0 & 0 & 0 & 1 & 0 \\
  0 & 0 & 0 & 0 & 1 \\
  0 & 0 & 0 & 0 & 0
  \end{bmatrix}.$$

## 模块职责
1. $v_1$：负责文本分片与清洗。
2. $v_2$：调用 LTP 的 `pipeline` 完成命名实体识别。
3. $v_3$：基于正则提取 ASCII/混合标识。
4. $v_4$：执行归一化、过滤、权重合并，并加载 `data/chinese_frequency_word.json`、`data/chinese_name_frequency_word.json` 构成带编号的字符二元词表（元素结构为 `{id, word}`，前缀 `1/2` 区分来源）；字符模式下读取真值二元组 $g_t$，令 $b_t = g_t[0] \Vert \hat{y}_t$，命中词表即输出奖励并写入指标 `lexical_bigram_candidate`，同时注入质量加权（基础 0.5，潜在 0.25）及教师回退奖励。
5. $v_5$：排序并写出 JSON。

## 拓扑伪代码
```pseudo
function ExecuteNetwork(chunks):
    q1 <- preprocess(chunks)         # v1
    ner_stream <- ltp_ner(q1)        # v2
    ascii_stream <- ascii_extract(q1) # v3
    bigram_vocab <- load_bigrams(["data/chinese_frequency_word.json", "data/chinese_name_frequency_word.json"])
    merged <- normalize_merge(ner_stream, ascii_stream, bigram_vocab) # v4
    # 环境内部按 base=0.5、potential=0.25、fallback=0.5 调整字符模式奖励
    return emit_json(merged, bigram_vocab)         # v5
```
